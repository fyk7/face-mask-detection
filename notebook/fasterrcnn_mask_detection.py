# -*- coding: utf-8 -*-
"""FasterRCNN_mask_detection.ipynb

Automatically generated by Colaboratory.
"""

import os
import re
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from tqdm import tqdm
import torchvision
from torchvision import transforms, datasets, models
import torch
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from PIL import Image
import matplotlib.pyplot as plt
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
import matplotlib.patches as patches

image_dir = 'drive/MyDrive/archive/images'
annotation_dir = 'drive/MyDrive/archive/annotations'

imgs_name_list = list(sorted(os.listdir(image_dir)))
annos_name_list = list(sorted(os.listdir(annotation_dir)))

df_imgs_annos = pd.DataFrame(
    {'imgs': imgs_name_list, 'annos': annos_name_list})
df_imgs_annos.head()

# Sort images and annotations by their file name.
df_imgs_annos.index = df_imgs_annos['imgs'].apply(
    lambda x: int(re.search(r'[0-9]+', x)[0]))
df_imgs_annos = df_imgs_annos.sort_index()
df_imgs_annos.head()

# Split dataset for train and test.
df_imgs_annos_tr = df_imgs_annos[:800]
df_imgs_annos_te = df_imgs_annos[800:]


def _generate_box(obj):
    '''xmlの要素からbboxを取得'''
    xmin = int(obj.find('xmin').text)
    ymin = int(obj.find('ymin').text)
    xmax = int(obj.find('xmax').text)
    ymax = int(obj.find('ymax').text)

    return [xmin, ymin, xmax, ymax]


def _generate_label(obj):
    '''xmlの要素からlabelを取得'''
    if obj.find('name').text == "with_mask":
        return 1
    elif obj.find('name').text == "mask_weared_incorrect":
        return 2
    return 0  # background class


def generate_target(image_id, file):
    with open(file, 'r') as f:
        data = f.read()
        soup = BeautifulSoup(data, 'xml')
        objects = soup.find_all('object')

        num_obj = len(objects)

        boxes = []
        labels = []
        for obj in objects:
            boxes.append(_generate_box(obj))
            labels.append(_generate_label(obj))
        # We should convert varilable to type of torch.Tensor()
        boxes = torch.as_tensor(boxes, dtype=torch.float32)

        labels = torch.as_tensor(labels, dtype=torch.int64)
        image_id = torch.tensor([image_id])
        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        target["image_id"] = image_id

        return target


class MaskDataset(object):
    def __init__(self, df_imgs_annos, transforms):
        self.transforms = transforms
        self.df_imgs_annos = df_imgs_annos

    def __len__(self):
        # return len(self.images)
        return len(self.df_imgs_annos)

    def __getitem__(self, idx):
        '''idx情報を使用して、imgとtarget(label)を返す'''
        image_name = self.df_imgs_annos.loc[idx, 'imgs']
        labels_name = self.df_imgs_annos.loc[idx, 'annos']
        # image_dir = 'drive/MyDrive/archive/images'
        # annotation_dir = 'drive/MyDrive/archive/annotations'
        image_path = os.path.join(image_dir, image_name)
        label_path = os.path.join(annotation_dir, labels_name)
        img = Image.open(image_path).convert("RGB")

        target = generate_target(idx, label_path)  # bbox, labels
        if self.transforms is not None:
            img = self.transforms(img)
        return img, target


data_transforms = transforms.Compose([
    transforms.ToTensor(),
])


def collate_fn(batch):
    return tuple(zip(*batch))


dataset = MaskDataset(df_imgs_annos_tr, data_transforms)
data_loader = torch.utils.data.DataLoader(
    dataset, batch_size=4, collate_fn=collate_fn
)


def get_model(num_classes):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        pretrained=True)
    # replace the pre-trained head
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model


# Check if GPU is active or not.
torch.cuda.is_available()

"""## Train"""

model = get_model(num_classes=3)

device = torch.device(
    'cuda') if torch.cuda.is_available() else torch.device('cpu')

# dataloaderが正常に動作しているかを確認
for imgs, annos in data_loader:
    imgs = list(img.to(device) for img in imgs)
    annos = [{k: v.to(device) for k, v in target.items()} for target in annos]
    print(f'imgs size: {len(imgs)}')
    print(imgs[0].shape)

    print(f'annos size: {len(annos)}')
    print(annos[0].keys())
    print(annos[0]['boxes'].shape)
    break

num_epochs = 25
# num_epochs = 10
model.to(device)

params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(
    params, lr=0.005, momentum=0.9, weight_decay=0.0005)
len_dataloader = len(data_loader)

for epoch in range(num_epochs):
    model.train()
    counter = 0
    epoch_loss = 0
    # for i, imgs, annotations in enumerate(tqdm(data_loader)):
    for imgs, annotations in tqdm(data_loader):
        counter += 1
        imgs = list(img.to(device) for img in imgs)
        annotations = [{k: v.to(device) for k, v in t.items()}
                       for t in annotations]
        loss_dict = model([imgs[0]], [annotations[0]])
        losses = sum(loss for loss in loss_dict.values())

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        if counter % 100 == 0:
            print(f'Iteration: {counter}/{len_dataloader}, Loss: {losses}')
        epoch_loss += losses
    print(epoch_loss)

model_save_path = 'drive/MyDrive/archive/model2.pt'

# Be carefull to overwirte saved model by not trained model.
# for gpu inference
# torch.save(model.state_dict(), model_save_path)

# for cpu inference
# torch.save(loaded_model.to('cpu').state_dict(), model_save_cpu_path)

"""## Inference"""

loaded_model = get_model(num_classes=3)

model_save_path = 'drive/MyDrive/archive/model2.pt'
device = torch.device(
    'cuda') if torch.cuda.is_available() else torch.device('cpu')

loaded_model.load_state_dict(torch.load(model_save_path))
loaded_model.eval()
loaded_model.to(device)

# cv2
# img = cv2.imread(imgfile)
# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
# image_tensor = torchvision.transforms.functional.to_tensor(img)

img = Image.open(
    '/content/drive/MyDrive/archive/images/maksssksksss850.png').convert("RGB")
img = data_transforms(img)  # to torch.Tensor()
print(img.shape)

with torch.no_grad():
    # model input shuld be list of images
    preds = loaded_model([img.to(device)])

preds


def plot_img_with_annos(img_tensor, annotation):

    fig, ax = plt.subplots(1)
    img = img_tensor.cpu().data

    # Display the image
    ax.imshow(img.permute(1, 2, 0))

    for box in annotation["boxes"]:
        xmin, ymin, xmax, ymax = box

        # Create a Rectangle patch
        rect = patches.Rectangle(
            (xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')

        # Add the patch to the Axes
        ax.add_patch(rect)

    plt.show()


plot_img_with_annos(img, preds[0])
# plot_image_with_annos(img_single[0], preds[0])

# save as png
# plt.savefig('../media/figure_with_annos.png') # -----(2)
